{
  "source_file": "Time to rethink your knowledge management _ LinkedIn.html",
  "processed_at": "2025-08-03T09:37:07.269943",
  "title": "Time to rethink your knowledge management",
  "url": "Unknown URL",
  "content": "The basic Ai tools of the hour\nI think you’ve seen this over and over again. The customer has a need. Sales talks to customer and finds out what they want. Sales talks to product and information is transferred. Product talks to the team and things are written down in specifications or backlog. This happens over and over.\nWe talk, chat and write down information. We redo the format over and over again inside the company. We are translators and information-mediators.\nI’m not saying this produces invalid results. I’m just saying that makes the process very slow. Most of the detailed original information is lost before we start creating the product.\nThe inefficiency is in plain sight. Our routine tends to hide the efficacy of our current ways. We are so used to how we work currently. We have sync meetings. We have calls to transfer information. We still fill out all kinds of forms to pass along information.\nThe LLM is the basic Ai tool for today\nA large language model (LLM) tool such as ChatGPT or Claude has become the focal point of knowledge creation.\nChatGPT or Claude to crunch through summaries and basic analysis\nThe ChatGPT and Claude are my go-to tools for working through basic information. I take transcripts out of the meetings and interviews. I summarise and shift through the material finding the essential parts. This all collects the body of information which is stored as text files. (See next point too)\nThe Ai tool is also used as basis for suggestions, viewpoint and basic review of work products.\nThis all produces intermediate analysis and lots of data. This body of knowledge is not the whole truth but pieces of the puzzle. In my old personal practise, this used to be scattered in Miro boards, long word file or basically in my head. Now the cost of intermediate analysis is going so much down. I do more of intermediate results. This is all to support richer recombination at later stages.\nFolders on the cloud to store intermediate results.\nMy thinking is that text-based storage is the optimal way to store knowledge for the months to come. This is because ChatGPT and the competitors eat in text still much better than visual formats.\nI end up with a lot of files in folders.\nThese files and folders become the context where you can unleash the Ai. Ai is generative but without context and intent it ends up outputting generalities. Or if you ask Ai to ideate freely, then you still need to context to evaluate what is good and what is bad.\nAi-based prototyping tools to experiment with possibilities.\nPrompt-based prototyping is already possible. Just try out\nCursor Ai\nfor instance. You will get a plausible product interface in minutes. For simple web user interfaces, you can even do this inside the\nClaude.ai\nprompt window.\nThe race is on to create the agent-based coding tools where you just give the intent. Then the agents will do the coding and testing. The results today are not 100% right code. We get something like 60% and plenty of gaps. But this is very much enough to make prototypes which are not mean for production use.\nThen you take your prototype and you show it inside the company and to potential customers. You go back to recording information and analysis. What used to be days collapses to hours.\nIf you think you cannot do it, I encourage you to try it out. Basic prompting skill will get you going.\nThe list can be short - The list will be long\nYou get very far with ChatGPT or Claude. Just get the paid version and you get going. Then bit by bit you will find an ecosystem of emerging tools for all sub use cases of value creation. The field of Ai is of course booming. The list of optimal tools keeps changing on the weekly basis.\nAs with all other fields, you start with basics and work your way upward.\nThe changes at hand\nMuch more information will be stored. This information is directly accessible without re-reading. Cost of analysis collapses. We have many inputs, and we quickly build the detail into the context in the LLM.\nWe have generative option-creation. We evaluate options with prompts. We prototype the interesting ones with Ai.\nLarge language models are exactly the tool for working with, analysing and recombining large sets of information - text being the most accessible format today.\nWe are democratising innovation. It is not only the product manager with the dev team who can create well-formed product increments in the near future. I think a handy sales person in a company with right enablement will be able to do this very soon. The classical value chain could be really rethought.\nHuman taste still needed. The need of differentiation will still be there. I hold that our collective team intelligence will still do that. But we will find more effective ways to do that too.\nThe old quote is fitting: “They say the future is already here; it is just not very evenly distributed. “",
  "content_html": "<div class=\"reader-article-content reader-article-content--content-blocks\" dir=\"ltr\">\n<div class=\"reader-content-blocks-container\" tabindex=\"0\">\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1940\">\n<em><!-- -->The basic Ai tools of the hour<!-- --></em>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1941\">\n<span class=\"white-space-pre\"> </span><!-- --><!-- -->\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1942\">\n<!-- --><!-- --><!-- -->\n<br/>\n</p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- --><!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<hr class=\"reader-divider-block__horizontal-rule\"/>\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1943\">\n<!-- -->I think you’ve seen this over and over again. The customer has a need. Sales talks to customer and finds out what they want. Sales talks to product and information is transferred. Product talks to the team and things are written down in specifications or backlog. This happens over and over.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1944\">\n<!-- -->We talk, chat and write down information. We redo the format over and over again inside the company. We are translators and information-mediators.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1945\">\n<!-- -->I’m not saying this produces invalid results. I’m just saying that makes the process very slow. Most of the detailed original information is lost before we start creating the product.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1946\">\n<!-- -->The inefficiency is in plain sight. Our routine tends to hide the efficacy of our current ways. We are so used to how we work currently. We have sync meetings. We have calls to transfer information. We still fill out all kinds of forms to pass along information.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<h2 class=\"ember-view reader-text-block__heading-2\" id=\"ember1947\">\n<!-- -->The LLM is the basic Ai tool for today<!-- -->\n<!-- --> </h2>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1948\">\n<!-- -->A large language model (LLM) tool such as ChatGPT or Claude has become the focal point of knowledge creation.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1949\">\n<strong><!-- -->ChatGPT or Claude to crunch through summaries and basic analysis<!-- --></strong>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1950\">\n<!-- -->The ChatGPT and Claude are my go-to tools for working through basic information. I take transcripts out of the meetings and interviews. I summarise and shift through the material finding the essential parts. This all collects the body of information which is stored as text files. (See next point too)<!-- -->\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1951\">\n<!-- -->The Ai tool is also used as basis for suggestions, viewpoint and basic review of work products.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1952\">\n<!-- -->This all produces intermediate analysis and lots of data. This body of knowledge is not the whole truth but pieces of the puzzle. In my old personal practise, this used to be scattered in Miro boards, long word file or basically in my head. Now the cost of intermediate analysis is going so much down. I do more of intermediate results. This is all to support richer recombination at later stages.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1953\">\n<strong><!-- -->Folders on the cloud to store intermediate results.<span class=\"white-space-pre\"> </span></strong>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1954\">\n<!-- -->My thinking is that text-based storage is the optimal way to store knowledge for the months to come. This is because ChatGPT and the competitors eat in text still much better than visual formats.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1955\">\n<!-- -->I end up with a lot of files in folders.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1956\">\n<!-- -->These files and folders become the context where you can unleash the Ai. Ai is generative but without context and intent it ends up outputting generalities. Or if you ask Ai to ideate freely, then you still need to context to evaluate what is good and what is bad.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1957\">\n<strong><!-- -->Ai-based prototyping tools to experiment with possibilities.<!-- --></strong>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1958\">\n<!-- -->Prompt-based prototyping is already possible. Just try out<span class=\"white-space-pre\"> </span><a class=\"cpepkcOjzZyNtQUIXJKATWOdxwsnbcwEPA\" data-test-app-aware-link=\"\" href=\"https://cursor.com/\" tabindex=\"0\" target=\"_self\"><!-- -->Cursor Ai<!-- --></a><span class=\"white-space-pre\"> </span>for instance. You will get a plausible product interface in minutes. For simple web user interfaces, you can even do this inside the<span class=\"white-space-pre\"> </span><a class=\"cpepkcOjzZyNtQUIXJKATWOdxwsnbcwEPA\" data-test-app-aware-link=\"\" href=\"http://claude.ai/\" tabindex=\"0\" target=\"_self\"><!-- -->Claude.ai<!-- --></a><span class=\"white-space-pre\"> </span>prompt window.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1959\">\n<!-- -->The race is on to create the agent-based coding tools where you just give the intent. Then the agents will do the coding and testing. The results today are not 100% right code. We get something like 60% and plenty of gaps. But this is very much enough to make prototypes which are not mean for production use.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1960\">\n<!-- -->Then you take your prototype and you show it inside the company and to potential customers. You go back to recording information and analysis. What used to be days collapses to hours.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1961\">\n<!-- -->If you think you cannot do it, I encourage you to try it out. Basic prompting skill will get you going.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1962\">\n<strong><!-- -->The list can be short - The list will be long<!-- --></strong>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1963\">\n<!-- -->You get very far with ChatGPT or Claude. Just get the paid version and you get going. Then bit by bit you will find an ecosystem of emerging tools for all sub use cases of value creation. The field of Ai is of course booming. The list of optimal tools keeps changing on the weekly basis.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1964\">\n<!-- -->As with all other fields, you start with basics and work your way upward.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<h2 class=\"ember-view reader-text-block__heading-2\" id=\"ember1965\">\n<!-- -->The changes at hand<!-- -->\n<!-- --> </h2>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1966\">\n<!-- -->Much more information will be stored. This information is directly accessible without re-reading. Cost of analysis collapses. We have many inputs, and we quickly build the detail into the context in the LLM.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1967\">\n<!-- -->We have generative option-creation. We evaluate options with prompts. We prototype the interesting ones with Ai.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1968\">\n<!-- -->Large language models are exactly the tool for working with, analysing and recombining large sets of information - text being the most accessible format today.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1969\">\n<!-- -->We are democratising innovation. It is not only the product manager with the dev team who can create well-formed product increments in the near future. I think a handy sales person in a company with right enablement will be able to do this very soon. The classical value chain could be really rethought.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1970\">\n<!-- -->Human taste still needed. The need of differentiation will still be there. I hold that our collective team intelligence will still do that. But we will find more effective ways to do that too.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1971\">\n<!-- -->The old quote is fitting: “They say the future is already here; it is just not very evenly distributed. “<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- --> </div>\n</div>",
  "content_markdown": "*The basic Ai tools of the hour*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n---\n\n\n\n\nI think you’ve seen this over and over again. The customer has a need. Sales talks to customer and finds out what they want. Sales talks to product and information is transferred. Product talks to the team and things are written down in specifications or backlog. This happens over and over.\n\n\n\n\n\n\n\nWe talk, chat and write down information. We redo the format over and over again inside the company. We are translators and information-mediators.\n\n\n\n\n\n\n\nI’m not saying this produces invalid results. I’m just saying that makes the process very slow. Most of the detailed original information is lost before we start creating the product.\n\n\n\n\n\n\n\nThe inefficiency is in plain sight. Our routine tends to hide the efficacy of our current ways. We are so used to how we work currently. We have sync meetings. We have calls to transfer information. We still fill out all kinds of forms to pass along information.\n\n\n\n\n\n\n\n## The LLM is the basic Ai tool for today\n\n\n\n\n\n\n\nA large language model (LLM) tool such as ChatGPT or Claude has become the focal point of knowledge creation.\n\n\n\n\n\n\n\n**ChatGPT or Claude to crunch through summaries and basic analysis**\n\n\n\n\n\n\n\nThe ChatGPT and Claude are my go-to tools for working through basic information. I take transcripts out of the meetings and interviews. I summarise and shift through the material finding the essential parts. This all collects the body of information which is stored as text files. (See next point too)\n\n\n\n\n\n\n\nThe Ai tool is also used as basis for suggestions, viewpoint and basic review of work products.\n\n\n\n\n\n\n\nThis all produces intermediate analysis and lots of data. This body of knowledge is not the whole truth but pieces of the puzzle. In my old personal practise, this used to be scattered in Miro boards, long word file or basically in my head. Now the cost of intermediate analysis is going so much down. I do more of intermediate results. This is all to support richer recombination at later stages.\n\n\n\n\n\n\n\n**Folders on the cloud to store intermediate results.**\n\n\n\n\n\n\n\nMy thinking is that text-based storage is the optimal way to store knowledge for the months to come. This is because ChatGPT and the competitors eat in text still much better than visual formats.\n\n\n\n\n\n\n\nI end up with a lot of files in folders.\n\n\n\n\n\n\n\nThese files and folders become the context where you can unleash the Ai. Ai is generative but without context and intent it ends up outputting generalities. Or if you ask Ai to ideate freely, then you still need to context to evaluate what is good and what is bad.\n\n\n\n\n\n\n\n**Ai-based prototyping tools to experiment with possibilities.**\n\n\n\n\n\n\n\nPrompt-based prototyping is already possible. Just try out [Cursor Ai](https://cursor.com/) for instance. You will get a plausible product interface in minutes. For simple web user interfaces, you can even do this inside the [Claude.ai](http://claude.ai/) prompt window.\n\n\n\n\n\n\n\nThe race is on to create the agent-based coding tools where you just give the intent. Then the agents will do the coding and testing. The results today are not 100% right code. We get something like 60% and plenty of gaps. But this is very much enough to make prototypes which are not mean for production use.\n\n\n\n\n\n\n\nThen you take your prototype and you show it inside the company and to potential customers. You go back to recording information and analysis. What used to be days collapses to hours.\n\n\n\n\n\n\n\nIf you think you cannot do it, I encourage you to try it out. Basic prompting skill will get you going.\n\n\n\n\n\n\n\n**The list can be short - The list will be long**\n\n\n\n\n\n\n\nYou get very far with ChatGPT or Claude. Just get the paid version and you get going. Then bit by bit you will find an ecosystem of emerging tools for all sub use cases of value creation. The field of Ai is of course booming. The list of optimal tools keeps changing on the weekly basis.\n\n\n\n\n\n\n\nAs with all other fields, you start with basics and work your way upward.\n\n\n\n\n\n\n\n## The changes at hand\n\n\n\n\n\n\n\nMuch more information will be stored. This information is directly accessible without re-reading. Cost of analysis collapses. We have many inputs, and we quickly build the detail into the context in the LLM.\n\n\n\n\n\n\n\nWe have generative option-creation. We evaluate options with prompts. We prototype the interesting ones with Ai.\n\n\n\n\n\n\n\nLarge language models are exactly the tool for working with, analysing and recombining large sets of information - text being the most accessible format today.\n\n\n\n\n\n\n\nWe are democratising innovation. It is not only the product manager with the dev team who can create well-formed product increments in the near future. I think a handy sales person in a company with right enablement will be able to do this very soon. The classical value chain could be really rethought.\n\n\n\n\n\n\n\nHuman taste still needed. The need of differentiation will still be there. I hold that our collective team intelligence will still do that. But we will find more effective ways to do that too.\n\n\n\n\n\n\n\nThe old quote is fitting: “They say the future is already here; it is just not very evenly distributed. “",
  "content_length": 4878,
  "publish_date": "Unknown date",
  "author": "Antti Tevanlinna",
  "slug": "time-to-rethink-your-knowledge-management"
}