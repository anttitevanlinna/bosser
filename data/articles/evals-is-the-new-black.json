{
  "source_file": "Evals is the new black _ LinkedIn.html",
  "processed_at": "2025-08-03T09:37:06.688725",
  "title": "Evals is the new black",
  "url": "Unknown URL",
  "content": "Not knowing beforehand is OK\nEvals are how you measure the quality and effectiveness of your AI system. This is a new term that I see trending a bit. An eval tells if you got the solution right or not. A simple as that on the surface.\nI find this progression very logical. LLMs and Ai cannot be strictly controlled to exact precision. There will always be an element of surprise in the output and outcomes.\nI’ve for long wanted to hear admissions of not knowing and making errors in product work. To me, this has always been human. Alas, many of the real-life work settings have still been about knowing and being right - always. We’ve kind of pretended to know more than we really know. This has been so in engineering. The same requirement of knowing it right has been in product management too. With Ai, that expectation of a priori certainty is no longer there. Now we can really embrace the iteration, failing initially and then correcting ourselves.\n(Side note: the certainty was never there even without Ai and LLMs. We just often pretended we know and get everything right by ourselves.)\nEvals come in many forms: Metrics and telemetry; LLM-based second checks and evaluations; and of course Human in the loop watching. The common denominator is investing into sensing for correctness of the product in real use.\nGenie and the lion tamer\nIn my imagination, I’ve had this metaphor of genie and the lion tamer as the duality of Ai. The Ai is the genie. Just like in the Aladdin movie the genie is a bit wonky and out of control. The genie has an abundance of ideas - too many. Many of the ideas don’t really fit as good solutions. You certainly can’t trust the genie.\nThe lion tamer is the control of the genie. He cracks his whip and keeps the genie in control. He watches and brings the show back to order.\nEvals is the lion tamer. Actually not quite. Evals is the eyes of the lion tamer. Evals notices when things are not going right. Then we need somebody to do something about the situation.\nInvesting in being in control - Having a system of being eventually in control\nMake the effort to know what is right and wrong in the business. Ai can generate anything - both right and utterly wrong. It is still your responsibility to tell what is right and wrong. In a way, to tell what is real and what is hallucinations.\nMake the investment proactively. Put in the sensing with and for the customers. Then you can have Ai search for an optimal solution. Evals is the sensing.\nYou cannot know everything a priori. That foresight just does not exits. That foresight certainly doesn’t exist the complex word where we are living in. The future is unpredictable and often surprising. Predictions will be wrong. This however does not mean that we could not understand and sense. The uncertainty does not mean that anything goes. There are righter and wronger solutions. It is for you to know the difference.\nNot knowing beforehand is OK. Not putting the effort to understand and gain knowledge is not OK. I welcome the shift to more exploratory approaches. To me, this is just one more step to more agility.\nNow what are evals in practice? That’s for you to imagine and build. Looking forward to hearing about your novel approaches.",
  "content_html": "<div class=\"reader-article-content reader-article-content--content-blocks\" dir=\"ltr\">\n<div class=\"reader-content-blocks-container\" tabindex=\"0\">\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1041\">\n<em><!-- -->Not knowing beforehand is OK<!-- --></em>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1042\">\n<!-- --><!-- --><!-- -->\n<br/>\n</p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1043\">\n<!-- --><!-- --><!-- -->\n<br/>\n</p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- --><!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<hr class=\"reader-divider-block__horizontal-rule\"/>\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1044\">\n<span class=\"white-space-pre\"> </span><!-- --><!-- -->\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1045\">\n<!-- -->Evals are how you measure the quality and effectiveness of your AI system. This is a new term that I see trending a bit. An eval tells if you got the solution right or not. A simple as that on the surface.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1046\">\n<!-- -->I find this progression very logical. LLMs and Ai cannot be strictly controlled to exact precision. There will always be an element of surprise in the output and outcomes.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1047\">\n<!-- -->I’ve for long wanted to hear admissions of not knowing and making errors in product work. To me, this has always been human. Alas, many of the real-life work settings have still been about knowing and being right - always. We’ve kind of pretended to know more than we really know. This has been so in engineering. The same requirement of knowing it right has been in product management too. With Ai, that expectation of a priori certainty is no longer there. Now we can really embrace the iteration, failing initially and then correcting ourselves.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1048\">\n<!-- -->(Side note: the certainty was never there even without Ai and LLMs. We just often pretended we know and get everything right by ourselves.)<!-- -->\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1049\">\n<!-- -->Evals come in many forms: Metrics and telemetry; LLM-based second checks and evaluations; and of course Human in the loop watching. The common denominator is investing into sensing for correctness of the product in real use.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<h2 class=\"ember-view reader-text-block__heading-2\" id=\"ember1050\">\n<!-- -->Genie and the lion tamer<!-- -->\n<!-- --> </h2>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1051\">\n<!-- -->In my imagination, I’ve had this metaphor of genie and the lion tamer as the duality of Ai. The Ai is the genie. Just like in the Aladdin movie the genie is a bit wonky and out of control. The genie has an abundance of ideas - too many. Many of the ideas don’t really fit as good solutions. You certainly can’t trust the genie.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1052\">\n<!-- -->The lion tamer is the control of the genie. He cracks his whip and keeps the genie in control. He watches and brings the show back to order.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1053\">\n<!-- -->Evals is the lion tamer. Actually not quite. Evals is the eyes of the lion tamer. Evals notices when things are not going right. Then we need somebody to do something about the situation.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<h2 class=\"ember-view reader-text-block__heading-2\" id=\"ember1054\">\n<!-- -->Investing in being in control - Having a system of being eventually in control<!-- -->\n<!-- --> </h2>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1055\">\n<!-- -->Make the effort to know what is right and wrong in the business. Ai can generate anything - both right and utterly wrong. It is still your responsibility to tell what is right and wrong. In a way, to tell what is real and what is hallucinations.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1056\">\n<!-- -->Make the investment proactively. Put in the sensing with and for the customers. Then you can have Ai search for an optimal solution. Evals is the sensing.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1057\">\n<!-- -->You cannot know everything a priori. That foresight just does not exits. That foresight certainly doesn’t exist the complex word where we are living in. The future is unpredictable and often surprising. Predictions will be wrong. This however does not mean that we could not understand and sense. The uncertainty does not mean that anything goes. There are righter and wronger solutions. It is for you to know the difference.<!-- -->\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1058\">\n<!-- -->Not knowing beforehand is OK. Not putting the effort to understand and gain knowledge is not OK. I welcome the shift to more exploratory approaches. To me, this is just one more step to more agility.<span class=\"white-space-pre\"> </span>\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<p class=\"ember-view reader-text-block__paragraph\" id=\"ember1059\">\n<!-- -->Now what are evals in practice? That’s for you to imagine and build. Looking forward to hearing about your novel approaches.<!-- -->\n<!-- --> </p>\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- -->\n<!-- --> </div>\n</div>",
  "content_markdown": "*Not knowing beforehand is OK*\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n---\n\n\n\n\n\n\n\n\n\nEvals are how you measure the quality and effectiveness of your AI system. This is a new term that I see trending a bit. An eval tells if you got the solution right or not. A simple as that on the surface.\n\n\n\n\n\n\n\nI find this progression very logical. LLMs and Ai cannot be strictly controlled to exact precision. There will always be an element of surprise in the output and outcomes.\n\n\n\n\n\n\n\nI’ve for long wanted to hear admissions of not knowing and making errors in product work. To me, this has always been human. Alas, many of the real-life work settings have still been about knowing and being right - always. We’ve kind of pretended to know more than we really know. This has been so in engineering. The same requirement of knowing it right has been in product management too. With Ai, that expectation of a priori certainty is no longer there. Now we can really embrace the iteration, failing initially and then correcting ourselves.\n\n\n\n\n\n\n\n(Side note: the certainty was never there even without Ai and LLMs. We just often pretended we know and get everything right by ourselves.)\n\n\n\n\n\n\n\nEvals come in many forms: Metrics and telemetry; LLM-based second checks and evaluations; and of course Human in the loop watching. The common denominator is investing into sensing for correctness of the product in real use.\n\n\n\n\n\n\n\n## Genie and the lion tamer\n\n\n\n\n\n\n\nIn my imagination, I’ve had this metaphor of genie and the lion tamer as the duality of Ai. The Ai is the genie. Just like in the Aladdin movie the genie is a bit wonky and out of control. The genie has an abundance of ideas - too many. Many of the ideas don’t really fit as good solutions. You certainly can’t trust the genie.\n\n\n\n\n\n\n\nThe lion tamer is the control of the genie. He cracks his whip and keeps the genie in control. He watches and brings the show back to order.\n\n\n\n\n\n\n\nEvals is the lion tamer. Actually not quite. Evals is the eyes of the lion tamer. Evals notices when things are not going right. Then we need somebody to do something about the situation.\n\n\n\n\n\n\n\n## Investing in being in control - Having a system of being eventually in control\n\n\n\n\n\n\n\nMake the effort to know what is right and wrong in the business. Ai can generate anything - both right and utterly wrong. It is still your responsibility to tell what is right and wrong. In a way, to tell what is real and what is hallucinations.\n\n\n\n\n\n\n\nMake the investment proactively. Put in the sensing with and for the customers. Then you can have Ai search for an optimal solution. Evals is the sensing.\n\n\n\n\n\n\n\nYou cannot know everything a priori. That foresight just does not exits. That foresight certainly doesn’t exist the complex word where we are living in. The future is unpredictable and often surprising. Predictions will be wrong. This however does not mean that we could not understand and sense. The uncertainty does not mean that anything goes. There are righter and wronger solutions. It is for you to know the difference.\n\n\n\n\n\n\n\nNot knowing beforehand is OK. Not putting the effort to understand and gain knowledge is not OK. I welcome the shift to more exploratory approaches. To me, this is just one more step to more agility.\n\n\n\n\n\n\n\nNow what are evals in practice? That’s for you to imagine and build. Looking forward to hearing about your novel approaches.",
  "content_length": 3233,
  "publish_date": "Unknown date",
  "author": "Antti Tevanlinna",
  "slug": "evals-is-the-new-black"
}